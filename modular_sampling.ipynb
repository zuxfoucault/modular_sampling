{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeIi12EGtT-o",
        "outputId": "399f3074-5711-476e-b97b-742c3753c52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final sample: [-0.96514876  0.39490618  0.74062475  0.68098171  0.63206278 -0.69542692\n",
            "  0.25237356 -0.60952134 -1.21766637 -0.86033093]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sample_correlated_noise(d, h, alpha):\n",
        "    \"\"\"\n",
        "    Generates joint Gaussian noise vectors (W1, W2, W3) based on\n",
        "    the Brownian motion simulation\n",
        "    \"\"\"\n",
        "    # Covariance for (G1, H1)\n",
        "    c_G1G1, c_H1H1 = 0.25 * (np.exp(4 * alpha * h) - 1), alpha * h\n",
        "    c_G1H1 = 0.5 * (np.exp(2 * alpha * h) - 1)\n",
        "\n",
        "    # Covariance for (G2, H2)\n",
        "    c_G2G2, c_H2H2 = 0.25 * (np.exp(4 * h) - np.exp(4 * alpha * h)), (1 - alpha) * h\n",
        "    c_G2H2 = 0.5 * (np.exp(2 * h) - np.exp(2 * alpha * h))\n",
        "\n",
        "    def sample_gaussian_pair(c_gg, c_hh, c_gh):\n",
        "        cov = [[c_gg, c_gh], [c_gh, c_hh]]\n",
        "        return np.random.multivariate_normal([0, 0], cov, size=d)\n",
        "\n",
        "    pair1, pair2 = (\n",
        "        sample_gaussian_pair(c_G1G1, c_H1H1, c_G1H1),\n",
        "        sample_gaussian_pair(c_G2G2, c_H2H2, c_G2H2),\n",
        "    )\n",
        "    G1, H1, G2, H2 = pair1[:, 0], pair1[:, 1], pair2[:, 0], pair2[:, 1]\n",
        "\n",
        "    # Reconstruct W vectors\n",
        "    W1 = H1 - np.exp(-2 * alpha * h) * G1\n",
        "    W2 = (H1 + H2) - np.exp(-2 * h) * (G1 + G2)\n",
        "    W3 = np.exp(-2 * h) * (G1 + G2)\n",
        "    return W1, W2, W3\n",
        "\n",
        "\n",
        "def randomized_midpoint_sampler(score_fn, x_init, num_steps, h=0.05, u=1.0):\n",
        "    \"\"\"\n",
        "    Black-box SLC sampler using Algorithm 1 (Randomized Midpoint)\n",
        "    \"\"\"\n",
        "    d = len(x_init)\n",
        "    x_n, v_n = x_init, np.zeros(d)\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        alpha = np.random.uniform(0, 1)  #\n",
        "        W1, W2, W3 = sample_correlated_noise(d, h, alpha)\n",
        "\n",
        "        # Intermediate position x_{n+1/2}\n",
        "        x_half = (\n",
        "            x_n\n",
        "            + 0.5 * (1 - np.exp(-2 * alpha * h)) * v_n\n",
        "            + 0.5 * u * (alpha * h - 0.5 * (1 - np.exp(-2 * alpha * h))) * score_fn(x_n)\n",
        "            + np.sqrt(u) * W1\n",
        "        )\n",
        "\n",
        "        # Final update x_{n+1} and v_{n+1}\n",
        "        x_next = (\n",
        "            x_n\n",
        "            + 0.5 * (1 - np.exp(-2 * h)) * v_n\n",
        "            + 0.5 * u * h * (1 - np.exp(-2 * (h - alpha * h))) * score_fn(x_half)\n",
        "            + np.sqrt(u) * W2\n",
        "        )\n",
        "        v_next = (\n",
        "            v_n * np.exp(-2 * h)\n",
        "            + u * h * np.exp(-2 * (h - alpha * h)) * score_fn(x_half)\n",
        "            + 2 * np.sqrt(u) * W3\n",
        "        )\n",
        "        x_n, v_n = x_next, v_next\n",
        "    return x_n\n",
        "\n",
        "\n",
        "def modular_sampling(target_score_fn, d, kappa, epsilon):\n",
        "    \"\"\"\n",
        "    Modular reduction to SLC sub-problems (Theorem 1 & 2)[cite: 35, 114].\n",
        "    \"\"\"\n",
        "    # Trajectory length K â‰ˆ 1 + log2(kappa)\n",
        "    K = int(np.ceil(1 + np.log2(max(2, kappa))))\n",
        "    s_k = 1.0 / (K + 1)  # Error budget sequence\n",
        "\n",
        "    # 1. Terminal Stage (Property T): Well-conditioned marginal pK\n",
        "    y_current = np.random.normal(0, 1, size=(d,))\n",
        "    M_k = kappa  # Initial condition number for the recursion\n",
        "\n",
        "    # 2. Backward Path (Property B): Solving SLC sub-problems\n",
        "    for k in reversed(range(K)):\n",
        "        # Calculate adaptive stepsize a_k for this round\n",
        "        # Chosen such that a_k^2 = Mk / (1 + Mk) ensures condition number <= 2\n",
        "        a_k_sq = M_k / (1 + M_k)\n",
        "        a_k = np.sqrt(a_k_sq)\n",
        "        b_sq = 1 - a_k_sq\n",
        "\n",
        "        def backward_conditional_score(u):\n",
        "            # Tweedie-based conditional score\n",
        "            return target_score_fn(u) - (a_k / b_sq) * (a_k * u - y_current)\n",
        "\n",
        "        # Solving the sub-problem using the high-accuracy root-dimension sampler\n",
        "        y_current = randomized_midpoint_sampler(\n",
        "            backward_conditional_score,\n",
        "            y_current,\n",
        "            num_steps=int(np.sqrt(d) * np.log(1 / (s_k * epsilon)) ** 3),\n",
        "            h=0.05,\n",
        "            u=1.0,  # Parameters for O(sqrt(d)) complexity\n",
        "        )\n",
        "\n",
        "        # Update Mk for the next stage in the backward sequence\n",
        "        M_k = 1 + 0.5 * (M_k - 1)\n",
        "\n",
        "    return y_current\n",
        "\n",
        "\n",
        "# Example Execution\n",
        "final_sample = modular_sampling(lambda x: -x, d=10, kappa=10, epsilon=1e-3)\n",
        "print(f\"Final sample: {final_sample}\")"
      ]
    }
  ]
}